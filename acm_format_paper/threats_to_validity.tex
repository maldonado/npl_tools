\noindent\textbf{Internal validity} consider the relationship between theory and observation, in case the measured variables do not measure the actual factors. The training dataset used by us heavily relied on manual analysis of the code comments from the studied projects. Like any human activity, our manual classification is subject to personal bias. To reduce this bias, we took a significant sample of our classified dataset and asked to a master student that was not working in this project to manually classify it. Then, we calculate the kappa's level of agreement between the classification given by the two different students. The level of agreement obtained was of \todo{}.  

When performing our study, we used well-commented Java projects. Since our technique heavily depends on code comments, our results and performance measures may be impacted by the quantity and quality of comments in a software project.  

\noindent \textbf{External validity} consider the generalization of our findings. All of our findings were derived from comments in open source projects. To minimize external validity, we chose open source projects from different domains. That said, our results may not generalize to other open source or commercial projects. In particular, our results may not generalize to projects that have a low number or no comments.
