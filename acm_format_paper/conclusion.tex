Technical debt is a term being used to express non optimal solutions, such as hacks and workarounds, that are applied during the software development process. Although these non optimal solutions can help achieve immediate pressing goals, most often they will have a negative impact in the project maintainability. 

Our work focuses on in the identification of \SATD through the use of Natural Processing Language. We analyzed the comments of 10 open source projects namely Apache Ant, Apache Jmeter, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JRuby and SQuirrel. These projects are considered well commented and they belong to different application domains.

The comments of these projects were manually classified into specif types of technical debt such as design, requirement, defect, documentation and test debt. This dataset with 63,015 comments were applied as training datasets to Stanford Classifier, and then this tool is used to identify  design and requirement \SATD automatically.

We first evaluated the performance of our approach by comparing our F1 measure with other two baselines F1 measure, the comment patterns baseline and the naive baseline. Our approach greatly outperform both baselines, in the identification of design \SATD, our F1 measure is 3.6 - 20.3 x better than best ranked baseline (i.e., comment patterns baseline). Similarly, while classifying requirement \SATD, we surpass the naive baseline by 6 - 54.4 times.

In addition, we explored the characteristics of the features (i.e., words) used to classify \SATD. We find that the words used to express design and requirement \SATD are different from each other. The three most strong indicators of design \SATD are `hack', `workaround' and `yuck!'. Whereas, `todo', `needed' and `implementation' are the strongest indicators of requirement debt.
 
Regarding the amount of data necessary to effectively identify \SATD comments using our approach we find that training datasets with at least 1,444 design debt comments can be used to identify \SATD. Similarly, datasets with at least 1,055 requirement debt comments can be used for the purpose of requirement \SATD identification. 

In this work, we contribute with the dataset created in this study making it publicly available, we believe that it will be a good starting point for researchers interested in identifying technical debt through comments and even using different types of Natural Processing Language techniques. 

More analysis is needed to fine tune the use of the current training dataset in order to achieve maximum efficiency in the prediction of \SATD comments. For example, using subsets of our training dataset can be more suitable for some applications than using the whole dataset due to domain particularities. 

However, the results thus far are not to be neglected as our approach performs 20 times better than the current state-of-the-art approach in some cases.

In a future work we will use the findings of this study to build a tool that will support software engineers in the task of identifying and managing the \SATD portfolio. We believe that our dataset can be used towards the effective identification of \SATD comments and it will be beneficial to the developer to see technical debt that was pointed out by other humans instead of relying only in metrics and thresholds. 