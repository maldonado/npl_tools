\documentclass{sig-alternate}\usepackage{amssymb,amsmath}\usepackage{wrapfig}\usepackage{multirow}\usepackage{graphicx}\usepackage{algorithm}\usepackage{algorithmic}\usepackage{times}\usepackage{cite}\usepackage{url}\usepackage{booktabs}\usepackage{fancybox}\usepackage{color}\usepackage{array}\usepackage{subfigure}\usepackage{balance}\usepackage{epstopdf}\usepackage{array}\usepackage{xspace}\usepackage{makecell}\usepackage{siunitx}\usepackage{caption}% author comments with colors \newcommand{\emad}[1]{\textcolor{red}{{\it [Emad: #1]}}}\newcommand{\nikos}[1]{\textcolor{red}{{\it [Nikos: #1]}}}\newcommand{\everton}[1]{\textcolor{blue}{{\it [Everton: #1]}}}\newcommand{\todo}[1]{\colorbox{yellow}{\textbf{[#1]}}}% conclusion box for summarize the research questions\newcommand{\conclusionbox}[1]{%       \vspace{2mm}       \framebox[0.45\textwidth][c]{%              \parbox[b]{0.42\textwidth}{%                     {\it #1}              }       }       \vspace{2mm}}% research questions \newcommand{\rqi}{\textbf{RQ1. Is it possible to effectively identify/predict \SATD using NLP techniques ?\\}}\newcommand{\rqii}{\textbf{RQ2. What are the most common words that indicates \SATD ?\\}}\newcommand{\rqiii}{\textbf{RQ3. How much training data is necessary for successfully predict \SATD ?\\}}% commands for common terms in the text\newcommand{\SATD}{self-admitted technical debt\xspace}\hyphenation{work-arounds}\begin{document}% --- Author Metadata here ---% \conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.% --- End of Author Metadata ---\title{Using Source Code Comments to Automatically Detect Self-Admitted Technical Debt}\numberofauthors{1} \author{\alignauthor        Everton da S. Maldonado, Nikolaos Tsantalis and Emad Shihab\\       \affaddr{Department of Computer Science and Software Engineering}\\       \affaddr{Concordia University, Montreal, Canada }\\       \email{e\_silvam@encs.concordia.ca, nikolaos.tsantalis@concordia.ca, emad.shihab@concordia.ca}}\maketitle\begin{abstract}During the development of a software system developers face unpredictable difficulties, and in many cases they apply unconventional solutions such as hacks and workarounds. The \textit{metaphor technical debt} was created to express this trade off between productivity and quality. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, this approach heavily depends on the manual classification of source comments. In this paper we present an approach to automatically identify design and requirement \SATD using a maximum entropy classifier. We studied ten open source projects: Apache Ant, Apache Jmeter, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JRuby and SQuirrel. We find that the average F1 measure achieved when identifying \SATD outperforms the state-of-the-art technique average F1 measure 1.9 to 20 times. During our analysis we evaluate and present the top 10 most common words that developers use to express technical debt. Lastly, we find that training datasets as small as 1,444 design debt comments and 601 requirement debt comments can be used to identify \SATD comments. To facilitate future work we make publicly available the dataset of classified comments used in this study containing more than 63K comments. \end{abstract}\terms{}\keywords{}\section{Introduction}\label{sec:introduction}Developers often have to deal with conflicting goals that require software to be delivered quickly, with high quality, and on budget. In practice, achieving all of these goals at the same time can be challenging, causing a tradeoff to be made. Often, these tradeoffs lead developers to take \emph{shortcuts} or use \emph{workarounds}. Although such shortcuts help developers in meeting their short-term goals, they may have a negative impact in the long-term.Technical debt is a metaphor coined to express sub-optimal solutions that are taken consciously in a software project in order to achieve some short-term goals~\cite{Cunningham1992WPM}. Generally, these decisions allow the project to move faster in the short-term, but introduce an increased cost (i.e., debt) to maintain this software in the long run~\cite{Seaman2011,Kruchten2013IWMTD}. Prior work has shown that technical debt is widespread in the software domain, is unavoidable, and can have a negative impact on the quality of the software~\cite{Lim2012Software}.Due to the importance of technical debt, a number of studies empirically examined technical debt and proposed techniques to enable its detection and management. The main findings of the prior work are that 1) there are different types of technical debt, e.g., defect debt, design debt, testing debt, and that among them design debt has the highest impact~\cite{Alves2014MTD,Marinescu2012IBM}. 2) Static source code analysis helps detecting technical debt, (i.e., code smells)~\cite{Marinescu2004ICSM,Marinescu2010CSMR,Zazworka2013CSE}. 3) More recently, our work shown that it is possible to identify technical debt through source comments (i.e., \SATD)~\cite{Potdar2014ICSME}, and that design and requirement debt are the most common types of \SATD~\cite{Maldonado2015MTD}.The research in \SATD, thus far, heavily relies on manual inspection of code comments. Manual inspection of code comments is subject to the reader bias, it is time consuming and, as any other manual task, susceptible to errors. These limitations in the identification of \SATD comments renders the current approach difficult to be applied.In this paper we investigate the efficiency of Natural Language Processing techniques to automatically detect the two most common types of \SATD comments, design and requirement debt. We analyze ten open source projects from different application domains, namely, Apache Ant, Apache Jmeter, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JRuby and SQuirrel. We extract and classify the source comments of these projects. Then, using the classified dataset we execute a maximum entropy classifier tool (i.e., the Stanford Classifier)~\cite{Manning2014ACL}, to identify design and requirement \SATD comments.We achieved an average F1 measure of 0.62 while identifying design \SATD, and an average F1 measure of 0.51 while identifying requirement \SATD. Which means that our performance is on average 8.6 times better than the current state-of-the-art approach to identify design \SATD, and 9.2 times better identifying requirement \SATD comments. The current-state-of-the art approach uses 64 comment patterns (i.e., words and phrases) derived after the manual examination of more than 100k comments.To better understand how developers express technical debt we analyze the 10 most prevalent words in \SATD comments. For example, words as `hack', `workaround' and `yuck!' are used to express design \SATD. Whereas, `todo', `needed' and `implementation' are a strong indicators of requirement debt.Then, to determine the most efficient way to apply our approach we analyze the amount of training data necessary to identify \SATD. We find that training datasets with at least 1,444 design \SATD comments can achieve good prediction performance. Similarly, for requirement \SATD, training datasets with at least 601 source comments containing requirement \SATD can identify this type of technical debt with success.  The contributions of our work are 1) we provide a automatic approach for identifying design and requirement \SATD. 2) We analyze the amount of necessary data to effectively apply our approach, making it possible to replicate our study in different contexts than ours (i.e., different idioms or programming languages). 3) We made the dataset used in this work publicly available. We believe that these are good contributions to future work in the area, and to researchers who are whiling to devise new approaches to address the problem of identifying technical debt through the use of code comments.% We also made the dataset used in this work publicly available. We believe that this is a good contribution to future work in the area, and to researchers who are whiling to devise new approaches to address the problem of identifying technical debt through the use of code comments.The rest of the paper is organized as follows. Section \ref{sec:approach} describes our approach. We setup our case study and present ourresults in Section \ref{sec:case_study_results}. We discuss the implication of our findings in Section \ref{sec:discussion}. In Section \ref{sec:related_work} we show related previous work. Section \ref{sec:threats_to_validity} present the threats to validity and Section \ref{sec:conclusion} presents our conclusions and future work.  \section{Approach}\label{sec:approach}\input{approach}\section{Case study Results}\label{sec:case_study_results}\input{results}\section{Discussion}\label{sec:discussion}\input{discussion}\section{Related Work}\label{sec:related_work}\input{related_work}\section{Threats to validity}\label{sec:threats_to_validity}\input{threats_to_validity}\section{Conclusion and Future work}\label{sec:conclusion}\input{conclusion}\bibliographystyle{abbrv}\bibliography{bibliography}  \include{appendix}\end{document}