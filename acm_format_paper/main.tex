\documentclass{sig-alternate}\usepackage{amssymb,amsmath}\usepackage{wrapfig}\usepackage{multirow}\usepackage{graphicx}\usepackage{algorithm}\usepackage{algorithmic}\usepackage{times}\usepackage{cite}\usepackage{url}\usepackage{booktabs}\usepackage{subfigure}\usepackage{fancybox}\usepackage{color}\usepackage{array}\usepackage{subfigure}\usepackage{balance}\usepackage{epstopdf}\usepackage{array}\usepackage{xspace}\usepackage{makecell}\usepackage{siunitx}% author comments with colors \newcommand{\emad}[1]{\textcolor{red}{{\it [Emad: #1]}}}\newcommand{\nikos}[1]{\textcolor{red}{{\it [Nikos: #1]}}}\newcommand{\everton}[1]{\textcolor{blue}{{\it [Everton: #1]}}}\newcommand{\todo}[1]{\colorbox{yellow}{\textbf{[#1]}}}% conclusion box for summarize the research questions\newcommand{\conclusionbox}[1]{%       \vspace{2mm}       \framebox[0.45\textwidth][c]{%              \parbox[b]{0.42\textwidth}{%                     {\it #1}              }       }       \vspace{2mm}}% research questions \newcommand{\rqi}{\textbf{RQ1. Is it possible to effectively identify/predict \SATD using NLP techniques ?\\}}\newcommand{\rqii}{\textbf{RQ2. What are the most common words that indicates \SATD ?\\}}\newcommand{\rqiii}{\textbf{RQ3. How much training data is necessary for successfully predict \SATD ?\\}}% commands for common terms in the text\newcommand{\SATD}{self-admitted technical debt\xspace}\hyphenation{work-arounds}\begin{document}% --- Author Metadata here ---% \conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.% --- End of Author Metadata ---\title{Using Source Code Comments to Automatically Detect Self-Admitted Technical Debt}\numberofauthors{1} \author{\alignauthor        Everton da S. Maldonado, Nikolaos Tsantalis and Emad Shihab\\       \affaddr{Department of Computer Science and Software Engineering}\\       \affaddr{Concordia University, Montreal, Canada }\\       \email{e\_silvam@encs.concordia.ca, nikolaos.tsantalis@concordia.ca, emad.shihab@concordia.ca}}\maketitle\begin{abstract}During the development of a software system developers face unpredictable difficulties, and in many cases they apply unconventional solutions such as hacks and workarounds. The metaphor technical debt was created to express this between productivity and quality. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, these approaches heavily depends on the manual classification of source comments hindering their use. In this paper we present an approach to automatically identify design and requirement \SATD using a maximum entropy classifier. We studied ten open source projects: Apache Ant, Apache Jmeter, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JRuby and SQuirrel, and we find that the average F1 measure when identifying design and requirement \SATD are 0.62 and 0.51 respectively. We also evaluate the top 10 most common words that developers use to express technical debt in the studied projects. Lastly, we find that training datasets containing approximately 1450 design debt comments and 1050 requirement debt comments can be used as reduced training datasets to identify \SATD comments. To facilitate future work we make publicly available the dataset of classified comments used in this study with more than 63K comments.  \end{abstract}\terms{}\keywords{}\section{Introduction}\label{sec:introduction}Developers often have to deal with conflicting goals that require software to be delivered quickly, with high quality, and on budget. In practice, achieving all of these goals at the same time can be challenging, causing a tradeoff to be made. Often, these tradeoffs lead developers to take \emph{shortcuts} or use \emph{workarounds}. Although such shortcuts help developers in meeting their short-term goals, they may have a negative impact in the long-term.Technical debt is a metaphor coined to express sub-optimal solutions that are taken consciously in a software project in order to achieve some short-term goals~\cite{Cunningham1992WPM}. Generally, these decisions allow the project to move faster in the short-term, but introduce an increased cost (i.e., debt) to maintain this software in the long run~\cite{Seaman2011,Kruchten2013IWMTD}. Prior work shown that technical debt is widespread in the software domain, is unavoidable, and can have a negative impact on the quality of the software~\cite{Lim2012Software}.Due to the importance of technical debt, a number of studies empirically examined it and proposed techniques to enable its detection and management. The main findings of the prior work are that 1) there are different types of technical debt, e.g., defect debt, design debt, testing debt, and that among them design debt has the highest impact~\cite{Alves2014MTD,Marinescu2012IBM}. 2) Static source code analysis helps detecting technical debt, (i.e., code smells)~\cite{Marinescu2004ICSM,Marinescu2010CSMR,Zazworka2013CSE}. 3) More recently, our work shown that it is possible to identify technical debt through source comments (i.e., \SATD)~\cite{Potdar2014ICSME}, and that design and requirement debt are the most common types of \SATD~\cite{Maldonado2015MTD}.This work uses comments to detect \emph{generic} technical debt, and did not focus on any specific type of technical debt. Based on this knowledge, Maldonado and Shihab~\cite{Maldonado2015MTD} showed that \emph{specific} types of self-admitted technical debt (i.e., design debt, requirement debt, defect debt, documentation debt and test debt) can be identified in code comments. Accordingly with their findings, the two most common types of \SATD comments are design debt and requirement debt. However, thus far relying on manual classification of \SATD comments renders the approach not appealing for use.Inspired in these previous work, in this paper we analyze the efficiency of Natural Language Processing techniques to detect the two most common types of \SATD comments, design debt and requirement debt. In order to do that, we analyze ten open source projects namely Apache Ant, Apache Jmeter, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JRuby and SQuirrel. We first extract the source comments of these projects. Then, we filter them removing comments that are not likely to have \SATD. The remainder of the source comments were manually classified into one of the different types of technical debt whenever possible. In total, we classified more than 63,000 comments. Using this classified dataset we execute a maximum entropy classifier tool (i.e., the Stanford Classifier), to identify design and requirement \SATD comments.We find that NLP techniques, such as maximum entropy classifiers, can be used effectively to find \SATD comments. We achieved an average F1 measure of 0.62 while identifying design \SATD, and an average F1 measure of 0.51 while classifying requirement \SATD. We also analyzed which are the more common words used to classify \SATD comments. We find that words such as `hack', `workaround' and `kludge' are a strong indicative of design \SATD. Whereas, `TODO:', `needed' and `implementation' are a strong indicative of requirement debt. We provide 10 more common words used by developers to express design and requirement technical debt.  Due to the fact that manual classification of code comments is a difficult task we explore ways to effectively identify \SATD using the least amount of data possible. We find that training datasets with at least 1,444 design \SATD comments can achieve good prediction performance. Similarly, for requirement \SATD, training datasets with at least 1,055 source comments containing requirement \SATD can identify this type of technical debt with success.  Lastly, we made the dataset used in this work publicly available. We believe that this is a good contribution to future work in the area, and to researchers who are whiling to devise new approaches to address the problem of identifying technical debt trough the use of code comments.The rest of the paper is organized as follows. Section \ref{sec:approach} describes our approach. We setup our case study and present ourresults in Section \ref{sec:case_study_results}. In Section \ref{sec:related_work} we show related previous work. Section \ref{sec:threats_to_validity} present the threats to validity and Section \ref{sec:conclusion} concludes our study.  \section{Approach}\label{sec:approach}\input{approach}\section{Case study Results}\label{sec:case_study_results}\input{results}\section{Discussion}\label{sec:discussion}\input{discussion}\section{Related Work}\label{sec:related_work}\input{related_work}\section{Threats to validity}\label{sec:threats_to_validity}\input{threats_to_validity}\section{Conclusion and Future work}\label{sec:conclusion}\input{conclusion}\bibliographystyle{abbrv}\bibliography{bibliography}  \include{appendix}\end{document}