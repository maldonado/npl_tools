% -*- root: main.tex -*-
Technical debt is a term being used to express non-optimal solutions, such as hacks and workarounds, that are applied during the software development process. Although these non-optimal solutions can help achieve immediate pressing goals, most often they will have a negative impact on the project maintainability~\cite{Zazworka2011MTD}. 

Our work focuses on the identification of \SATD through the use of Natural Language Processing. We analyzed the comments of 10 open source projects namely Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL. These projects are considered well commented and they belong to different application domains. The comments of these projects were manually classified into specific types of technical debt such as design, requirement, defect, documentation and test debt. Next, we selected 61,664 comments from this dataset (i.e., those classified as design \SATD, requirement \SATD and without technical debt) to train the \revised{maximum entropy classifier}{R2-11}, and then this classifier was used to identify  design and requirement \SATD automatically.

We first evaluated the performance of our approach by comparing the F1-measure of our approach with the F1-measure of two other baselines, i.e., the comment patterns baseline and the simple (random) baseline. We have shown that our approach outperforms the comment patterns baseline on average 2.3 and 6 times in the identification of design and requirement \SATD, respectively. Moreover, our approach can identify requirement \SATD, while the comment patterns baseline fails to detect this kind of debt in most of the examined projects. Furthermore, the performance of our approach surpasses the simple (random) baseline on average 7.6 and 19.1 times for design and requirement \SATD, respectively. 

\revised{Then,}{R3-8} we explored the characteristics of the features (i.e., words) used to classify \SATD. We find that the words used to express design and requirement \SATD are different from each other. The three strongest indicators of design \SATD are `hack', `workaround' and `yuck!', whereas, `todo', `needed' and `implementation' are the strongest indicators of requirement debt. In addition, we find that using only 5\% and 23\% of the comments in the training dataset still leads to an accuracy that is equivalent to 80\% and 90\% of the best performance, respectively. In fact, our results show that developers use a richer vocabulary to express design \SATD and a training dataset of at least 3,900 comments (of which 195 comments are design \SATD) is necessary to obtain a satisfactory classification. On the other hand, requirement \SATD is expressed in a more uniform way, and with a training dataset of 2,600 comments (of which 52 are \SATD) it is possible to classify with relatively high accuracy requirement \SATD.

In the future, we believe that more analysis is needed to fine tune the use of the current training dataset in order to achieve maximum efficiency in the detection of \SATD comments. For example, using subsets of our training dataset can be more suitable for some applications than using the whole dataset due to domain particularities. However, the results thus far are not to be neglected as our approach has the best F1-measure performance on every analyzed project. \revised{In addition, we plan to examine the applicability of our approach to more domains (than those we study in this paper) and software projects developed in different programming languages.}{R1-4}  

\revised{Another interesting research direction that we plan to investigate in the future is the use of other machine learning techniques, such as active learning to reduce the number of labeled data necessary to train the classifier. This technique, if proved successful, can further expand the horizon of projects that our approach can be applied to.}{R2-13}

Moreover, to enable future research, we make the dataset created in this study publicly available\footnote{\url{https://github.com/maldonado/tse.satd.data}}. We believe that it will be a good starting point for researchers interested in identifying technical debt through comments and even experimenting with different Natural Language Processing techniques. Lastly, we plan to use the findings of this study to build a tool that will support software engineers in the task of identifying and managing \SATD. 


% \emad{we have 3 results there....we really need to simply this and have 1 or max 2 results.}